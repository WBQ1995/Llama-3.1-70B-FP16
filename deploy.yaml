version: "2.0"
type: node-port
services:
  vm:
    image: vllm/vllm-openai:latest
    env:
      - HUGGING_FACE_HUB_TOKEN="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"
    args:
      [
        "--model", "meta-llama/Meta-Llama-3.1-70B-Instruct",
        "--dtype", "bfloat16",
        "--enforce-eager",
        "--gpu-memory-utilization", "0.95",
        "--max-model-len", "8128",
        "--tensor_parallel_size", "2"
      ]
    expose:
        - port: 8000

deployment:
  vm:
    lagrange:
      count: 1
